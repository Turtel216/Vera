// Copyright 2024 Dimitrios Papakonstantinou. All rights reserved.
// Use of this source code is governed by a MIT
// license that can be found in the LICENSE file
//
// This file contains the implementation the parser for Vera. It defines parsing rules
// and precedence, manages compiler state, and handles expressions, variables, and control flow structures.

use crate::object::ObjString;
use std::{collections::HashMap, u16};

use crate::{
    chunk::{Chunk, OpCode},
    lexer::{Token, TokenType},
    value::Value,
};

/// Enum representing the different levels of operator precedence.
/// This is used to determine the order of operations when parsing expressions.
#[derive(Copy, Clone, PartialOrd, PartialEq)]
enum Precedence {
    PrecNone,       // No precedence (default)
    PrecAssignment, // Assignment: `=`
    PrecOr,         // Logical OR: `or`
    PrecAnd,        // Logical AND: `and`
    PrecEquality,   // Equality comparisons: `==`, `!=`
    PrecComparison, // Comparisons: `<`, `>`, `<=`, `>=`
    PrecTerm,       // Addition and subtraction: `+`, `-`
    PrecFactor,     // Multiplication and division: `*`, `/`
    PrecUnary,      // Unary operators: `-`, `!`
    PrecCall,       // Function calls and property access: `()`, `.`
    PrecPrimary,    // Primary expressions (identifiers, literals)
}

impl Precedence {
    fn next(&self) -> Precedence {
        match self {
            Precedence::PrecNone => Precedence::PrecAssignment,
            Precedence::PrecAssignment => Precedence::PrecOr,
            Precedence::PrecOr => Precedence::PrecAnd,
            Precedence::PrecAnd => Precedence::PrecEquality,
            Precedence::PrecEquality => Precedence::PrecComparison,
            Precedence::PrecComparison => Precedence::PrecTerm,
            Precedence::PrecTerm => Precedence::PrecFactor,
            Precedence::PrecFactor => Precedence::PrecUnary,
            Precedence::PrecUnary => Precedence::PrecCall,
            Precedence::PrecCall => Precedence::PrecPrimary,
            Precedence::PrecPrimary => Precedence::PrecNone,
        }
    }
}

/// Type alias for a parsing function, which takes a mutable reference to the Parser
/// and a boolean flag indicating if assignment is allowed.
type ParseFn<'sourcecode> = fn(&mut Parser<'sourcecode>, bool) -> ();

/// A structure that defines how to parse a specific token type.
/// - `precedence`: The precedence level of the token.
/// - `prefix`: A function to parse the token when it appears at the beginning of an expression.
/// - `infix`: A function to parse the token when it appears in the middle of an expression.
#[derive(Copy, Clone)]
struct ParseRule<'p> {
    precedence: Precedence,
    prefix: Option<ParseFn<'p>>,
    infix: Option<ParseFn<'p>>,
}

impl<'p> ParseRule<'p> {
    fn new(
        prefix: Option<ParseFn<'p>>,
        infix: Option<ParseFn<'p>>,
        precedence: Precedence,
    ) -> ParseRule<'p> {
        ParseRule {
            precedence,
            prefix,
            infix,
        }
    }
}

#[derive(Clone)]
struct Local {
    name: Token,
    depth: isize,
}

/// The `Compiler` struct is responsible for managing local variables and scope depth during
/// the parsing process. It tracks local variables in a stack and manages entering and exiting
/// scope levels.
struct Compiler {
    locals: Vec<Local>, // Stack of local variables
    scope_depth: isize, // Current depth of nested scopes
}

impl Clone for Compiler {
    fn clone(&self) -> Self {
        Self {
            locals: self.locals.clone(),
            scope_depth: self.scope_depth,
        }
    }
}

impl Compiler {
    fn new() -> Self {
        Compiler {
            locals: Vec::new(),
            scope_depth: 0,
        }
    }

    fn reset_compiler(&mut self) -> () {
        self.locals.clear();
        self.scope_depth = 0;
    }
}

/// The `Parser` struct is the core of the parsing process. It holds the list of tokens,
/// manages the state of the current parsing operation, and emits bytecode to a `Chunk`.
/// - `tokens`: The token stream generated by the lexer.
/// - `chunk`: The bytecode chunk being emitted.
/// - `had_error`: A flag indicating if an error occurred during parsing.
/// - `panic_mode`: A flag indicating if the parser is in panic mode after an error.
/// - `current_compiler`: Manages the state of the current compiler (locals, scope depth).
pub struct Parser<'c> {
    current: usize,                           // Index of the current token being parsed
    tokens: &'c Vec<Token>,                   // List of tokens to be parsed
    pub chunk: &'c mut Chunk,                 // Bytecode chunk to emit instructions
    had_error: bool,                          // Tracks if any error occurred during parsing
    panic_mode: bool,                         // Tracks if the parser is in panic mode
    rules: HashMap<TokenType, ParseRule<'c>>, // Parsing rules for each token type
    current_compiler: Compiler, // State of the current compiler (local variables, scope depth)
}

impl<'c> Parser<'c> {
    pub fn new(tokens: &'c Vec<Token>, chunk: &'c mut Chunk) -> Self {
        let mut rules = HashMap::new();
        let mut rule = |kind, prefix, infix, precedence| {
            rules.insert(kind, ParseRule::new(prefix, infix, precedence));
        };

        //TODO add TokenMinusMinus and TokenPlusPlus

        rule(
            TokenType::TokenLeftParen,
            Some(Parser::grouping),
            None,
            Precedence::PrecNone,
        );
        rule(TokenType::TokenRightParen, None, None, Precedence::PrecNone);
        rule(TokenType::TokenLeftBrace, None, None, Precedence::PrecNone);
        rule(TokenType::TokenRightBrace, None, None, Precedence::PrecNone);
        rule(TokenType::TokenComma, None, None, Precedence::PrecNone);
        rule(TokenType::TokenDot, None, None, Precedence::PrecNone);
        rule(
            TokenType::TokenMinus,
            Some(Parser::unary),
            Some(Parser::binary),
            Precedence::PrecTerm,
        );
        rule(
            TokenType::TokenPlus,
            None,
            Some(Parser::binary),
            Precedence::PrecTerm,
        );
        rule(
            TokenType::TokenPow,
            None,
            Some(Parser::binary),
            Precedence::PrecTerm,
        );
        rule(
            TokenType::TokenShiftLeft,
            None,
            Some(Parser::binary),
            Precedence::PrecTerm,
        );
        rule(
            TokenType::TokenShiftRigth,
            None,
            Some(Parser::binary),
            Precedence::PrecTerm,
        );
        rule(TokenType::TokenSemicolon, None, None, Precedence::PrecNone);
        rule(
            TokenType::TokenSlash,
            None,
            Some(Parser::binary),
            Precedence::PrecFactor,
        );
        rule(
            TokenType::TokenStar,
            None,
            Some(Parser::binary),
            Precedence::PrecFactor,
        );
        rule(
            TokenType::TokenBang,
            Some(Parser::unary),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenBangEqual,
            None,
            Some(Parser::binary),
            Precedence::PrecEquality,
        );
        rule(TokenType::TokenEqual, None, None, Precedence::PrecNone);
        rule(
            TokenType::TokenEqualEqual,
            None,
            Some(Parser::binary),
            Precedence::PrecEquality,
        );
        rule(
            TokenType::TokenGreater,
            None,
            Some(Parser::binary),
            Precedence::PrecComparison,
        );
        rule(
            TokenType::TokenGreaterEqual,
            None,
            Some(Parser::binary),
            Precedence::PrecComparison,
        );
        rule(
            TokenType::TokenLess,
            None,
            Some(Parser::binary),
            Precedence::PrecComparison,
        );
        rule(
            TokenType::TokenLessEqual,
            None,
            Some(Parser::binary),
            Precedence::PrecComparison,
        );
        rule(
            TokenType::TokenIdentifier,
            Some(Parser::variable),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenString,
            Some(Parser::parse_string),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenNumber,
            Some(Parser::parse_number),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenTrue,
            Some(Parser::literal),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenFalse,
            Some(Parser::literal),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenNil,
            Some(Parser::literal),
            None,
            Precedence::PrecNone,
        );
        rule(
            TokenType::TokenAnd,
            None,
            Some(Parser::and_),
            Precedence::PrecAnd,
        );
        rule(TokenType::TokenClass, None, None, Precedence::PrecNone);
        rule(TokenType::TokenElse, None, None, Precedence::PrecNone);
        rule(
            TokenType::TokenFalse,
            Some(Parser::literal),
            None,
            Precedence::PrecNone,
        );
        rule(TokenType::TokenFor, None, None, Precedence::PrecNone);
        rule(TokenType::TokenFor, None, None, Precedence::PrecNone);
        rule(TokenType::TokenFun, None, None, Precedence::PrecNone);
        rule(TokenType::TokenIf, None, None, Precedence::PrecNone);
        rule(TokenType::TokenNil, None, None, Precedence::PrecNone);
        rule(
            TokenType::TokenOr,
            None,
            Some(Parser::or_),
            Precedence::PrecOr,
        );
        rule(TokenType::TokenPrint, None, None, Precedence::PrecNone);
        rule(TokenType::TokenReturn, None, None, Precedence::PrecNone);
        rule(TokenType::TokenTrue, None, None, Precedence::PrecNone);
        rule(TokenType::TokenVar, None, None, Precedence::PrecNone);
        rule(TokenType::TokenWhile, None, None, Precedence::PrecNone);
        rule(TokenType::TokenError, None, None, Precedence::PrecNone);
        rule(TokenType::TokenEOF, None, None, Precedence::PrecNone);

        return Parser {
            tokens,
            current: 0,
            had_error: false,
            panic_mode: false,
            chunk,
            rules,
            current_compiler: Compiler::new(),
        };
    }
    /// Compiles the provided tokens into bytecode.
    /// It iterates over all tokens, parsing declarations and statements, and emits corresponding bytecode.
    /// Returns `true` if compilation was successful without errors.
    pub fn compile(&mut self) -> bool {
        self.current_compiler.reset_compiler();

        while !self.match_token(TokenType::TokenEOF) {
            self.declaration(); // Parse top-level declaration
        }

        self.end_compiler();
        return !self.had_error; // Compilation success if no errors
    }

    /// Parses a top-level declaration. This could be a variable declaration or a statement.
    /// If an error occurs, the parser synchronizes to recover from the panic mode.
    fn declaration(&mut self) -> () {
        if self.match_token(TokenType::TokenVar) {
            self.var_declaration();
        } else {
            self.statement();
        }

        if self.panic_mode == true {
            self.synchronize(); // Recover from error by skipping to next valid statement
        }
    }

    fn statement(&mut self) -> () {
        if self.match_token(TokenType::TokenPrint) {
            self.print_statement();
        } else if self.match_token(TokenType::TokenLeftBrace) {
            self.begin_scope();
            self.block();
            self.end_scope();
        } else if self.match_token(TokenType::TokenIf) {
            self.if_statement();
        } else if self.match_token(TokenType::TokenWhile) {
            self.while_statement();
        } else {
            self.expression_statement();
        }
    }

    fn expression_statement(&mut self) -> () {
        self.expression();
        self.consume(TokenType::TokenSemicolon, "Expected ';' after expression");
        self.emit_byte(OpCode::OpPop);
    }

    fn if_statement(&mut self) -> () {
        self.consume(TokenType::TokenLeftParen, "Expected '(' after 'if..TODO'.");
        self.expression();
        self.consume(TokenType::TokenRightParen, "Expected ')' after condition.");

        let then_jump = self.emit_jump(OpCode::OpJumpIfFalse(0xffff)) as usize;
        self.emit_byte(OpCode::OpPop);
        self.statement();

        let else_jump = self.emit_jump(OpCode::OpJump(0xffff)) as usize;

        self.patch_jump(then_jump);

        self.emit_byte(OpCode::OpPop);

        if self.match_token(TokenType::TokenElse) {
            self.statement();
        }

        self.patch_jump(else_jump);
    }

    fn print_statement(&mut self) -> () {
        self.expression();
        self.consume(TokenType::TokenSemicolon, "Expected  ';' after value.");
        self.emit_byte(OpCode::OpPrint);
    }

    fn while_statement(&mut self) -> () {
        let loop_start = self.chunk.code.len();

        self.consume(TokenType::TokenLeftParen, "Expected '(' after 'TODO'.");
        self.expression();
        self.consume(TokenType::TokenRightParen, "Expected ')' after condition.");

        let exit_jump = self.emit_jump(OpCode::OpJumpIfFalse(0xff)) as usize;
        self.emit_jump(OpCode::OpPop);
        self.statement();
        self.emit_loop(loop_start);

        self.patch_jump(exit_jump);
        self.emit_byte(OpCode::OpPop);
    }

    fn var_declaration(&mut self) -> () {
        let global = self.parse_variable("Epxected variable name.");

        if self.match_token(TokenType::TokenEqual) {
            self.expression();
        } else {
            self.emit_byte(OpCode::OpNil);
        }

        self.consume(TokenType::TokenSemicolon, "Expected ';' after expression");

        self.define_variable(global);
    }

    fn parse_variable(&mut self, msg: &'c str) -> u8 {
        self.consume(TokenType::TokenIdentifier, msg);

        self.declare_variable();
        if self.current_compiler.scope_depth > 0 {
            return 0;
        }

        return self.identifier_constant(&self.tokens[self.current - 1]);
    }

    fn mark_initialized(&mut self) -> () {
        self.current_compiler
            .locals
            .last_mut()
            .unwrap_or_else(|| panic!("Could not get last local in mark_initialized"))
            .depth = self.current_compiler.scope_depth;
    }

    fn define_variable(&mut self, global: u8) -> () {
        if self.current_compiler.scope_depth > 0 {
            self.mark_initialized();
            return;
        }

        self.emit_byte(OpCode::OpDefineGlobal(global));
    }

    fn and_(&mut self, _can_assign: bool) -> () {
        let end_jump = self.emit_jump(OpCode::OpJumpIfFalse(0xff)) as usize;

        self.emit_byte(OpCode::OpPop);
        self.parse_precedence(Precedence::PrecAnd);

        self.patch_jump(end_jump);
    }

    fn declare_variable(&mut self) -> () {
        if self.current_compiler.scope_depth == 0 {
            return;
        }

        let name = self.tokens[self.current - 1].clone();

        // Check for duplicate names in scope and variable shadowing
        for local in self.current_compiler.locals.iter_mut() {
            if local.depth != -1 && local.depth < self.current_compiler.scope_depth {
                break;
            }

            if name.source_str == local.name.source_str {
                self.error("Already a variable with this name in this scope.");
                return; //TODO might cause bug
            }
        }

        self.add_local(name);
    }

    fn add_local(&mut self, name: Token) -> () {
        if self.current_compiler.locals.len() == u8::max_value().into() {
            self.error("Too many local variables in functino.");
            return;
        }

        self.current_compiler.locals.push(Local { name, depth: -1 });
    }

    fn identifier_constant(&mut self, name: &Token) -> u8 {
        return self.make_constant(Value::Object(ObjString {
            chars: name.source_str.clone(),
        }));
    }

    fn resolve_local(&mut self, compiler: Compiler, name: &Token) -> isize {
        for (i, local) in compiler.locals.iter().enumerate() {
            if name.source_str == local.name.source_str {
                if local.depth == -1 {
                    self.error("Can't read local variable in its own initializer.");
                }
                return i as isize;
            }
        }

        return -1;
    }

    fn synchronize(&mut self) -> () {
        self.panic_mode = false;

        while self.tokens[self.current]._type != TokenType::TokenEOF {
            if self.tokens[self.current - 1]._type == TokenType::TokenSemicolon {
                return;
            }

            match self.tokens[self.current]._type {
                TokenType::TokenClass => return,
                TokenType::TokenFun => return,
                TokenType::TokenVar => return,
                TokenType::TokenFor => return,
                TokenType::TokenIf => return,
                TokenType::TokenWhile => return,
                TokenType::TokenPrint => return,
                TokenType::TokenReturn => return,
                _ => self.advance(),
            }
        }
    }

    fn end_compiler(&mut self) -> () {
        self.emit_return();
    }

    fn advance(&mut self) -> () {
        self.current += 1;

        if self.current == self.tokens.len() {
            return;
        }

        if self.tokens[self.current]._type != TokenType::TokenError {
            return;
        }

        self.error_at_current(&self.tokens[self.current].source_str);
    }

    fn match_token(&mut self, _type: TokenType) -> bool {
        if !self.check(_type) {
            return false;
        }
        self.advance();
        return true;
    }

    fn check(&self, _type: TokenType) -> bool {
        return self.tokens[self.current]._type == _type;
    }

    fn expression(&mut self) -> () {
        self.parse_precedence(Precedence::PrecAssignment);
    }

    fn block(&mut self) -> () {
        while !self.check(TokenType::TokenRightBrace) && !self.check(TokenType::TokenEOF) {
            self.declaration();
        }

        self.consume(TokenType::TokenRightBrace, "Expected '}' after block.");
    }

    fn begin_scope(&mut self) -> () {
        self.current_compiler.scope_depth += 1;
    }

    fn end_scope(&mut self) -> () {
        self.current_compiler.scope_depth -= 1;

        // Free up locals
        while self.current_compiler.locals.len() > 0
            && self.current_compiler.locals.last().unwrap().depth
                > self.current_compiler.scope_depth
        {
            self.emit_byte(OpCode::OpPop);
            self.current_compiler.locals.pop();
        }
    }

    fn consume(&mut self, _type: TokenType, msg: &'c str) -> () {
        if self.tokens[self.current]._type == _type {
            self.advance();
            return;
        }

        self.error_at_current(msg);
    }

    fn grouping(&mut self, _can_assign: bool) -> () {
        self.expression();
        self.consume(TokenType::TokenRightParen, "Expect ')' after expression.");
    }

    fn unary(&mut self, _can_assign: bool) -> () {
        let operator_type = self.tokens[self.current - 1]._type;

        // Compile the operand
        self.parse_precedence(Precedence::PrecUnary);

        // Emit le operator instuction
        match operator_type {
            TokenType::TokenMinus => self.emit_byte(OpCode::OpNegate),
            TokenType::TokenBang => self.emit_byte(OpCode::OpNot),
            _ => return,
        }
    }

    fn binary(&mut self, _can_assign: bool) -> () {
        let operator_type = self.tokens[self.current - 1]._type;
        let rule = self.get_rule(operator_type);
        self.parse_precedence(rule.precedence.next());

        match operator_type {
            TokenType::TokenPlus => self.emit_byte(OpCode::OpAdd),
            TokenType::TokenMinus => self.emit_byte(OpCode::OpSubtract),
            TokenType::TokenStar => self.emit_byte(OpCode::OpMultiply),
            TokenType::TokenSlash => self.emit_byte(OpCode::OpDivide),
            TokenType::TokenPow => self.emit_byte(OpCode::OpPow),
            TokenType::TokenShiftLeft => self.emit_byte(OpCode::OpLeftShift),
            TokenType::TokenShiftRigth => self.emit_byte(OpCode::OpRightShift),
            TokenType::TokenBangEqual => self.emit_bytes(OpCode::OpEqual, OpCode::OpNot),
            TokenType::TokenEqualEqual => self.emit_byte(OpCode::OpEqual),
            TokenType::TokenGreater => self.emit_byte(OpCode::OpGreater),
            TokenType::TokenGreaterEqual => self.emit_bytes(OpCode::OpLess, OpCode::OpNot),
            TokenType::TokenLess => self.emit_byte(OpCode::OpLess),
            TokenType::TokenLessEqual => self.emit_bytes(OpCode::OpGreater, OpCode::OpNot),
            _ => panic!("Invalid binary operator!"),
        }
    }

    fn literal(&mut self, _can_assign: bool) -> () {
        match self.tokens[self.current - 1]._type {
            TokenType::TokenFalse => self.emit_byte(OpCode::OpFalse),
            TokenType::TokenTrue => self.emit_byte(OpCode::OpTrue),
            TokenType::TokenNil => self.emit_byte(OpCode::OpNil),
            _ => return,
        };
    }

    fn parse_string(&mut self, _can_assign: bool) -> () {
        self.emit_constant(Value::Object(ObjString {
            chars: self.tokens[self.current - 1].source_str.clone(),
        }));
    }

    fn variable(&mut self, can_assign: bool) -> () {
        self.named_variable(&self.tokens[self.current - 1], can_assign);
    }

    fn named_variable(&mut self, name: &Token, can_assign: bool) -> () {
        let (op_get, op_set) = match self.resolve_local(self.current_compiler.clone(), &name) {
            -1 => {
                let arg = self.identifier_constant(&name);
                (OpCode::OpGetGlobal(arg), OpCode::OpSetGlobal(arg))
            }
            arg => (OpCode::OpGetLocal(arg as u8), OpCode::OpSetLocal(arg as u8)),
        };

        if self.match_token(TokenType::TokenEqual) && can_assign {
            self.expression();
            self.emit_byte(op_set);
        } else {
            self.emit_byte(op_get);
        }
    }

    fn parse_precedence(&mut self, precedence: Precedence) -> () {
        self.advance();
        let prefix_rule = match self.get_rule(self.tokens[self.current - 1]._type).prefix {
            Some(rule) => rule,
            None => {
                println!("On type: {}", self.tokens[self.current - 1]._type);
                self.error("Expected expression");
                return;
            }
        };

        let can_assign = precedence <= Precedence::PrecAssignment;
        prefix_rule(self, can_assign);

        while self.is_lower_precedence(precedence) {
            self.advance();
            let infix_rule = self
                .get_rule(self.tokens[self.current - 1]._type)
                .infix
                .unwrap();
            infix_rule(self, can_assign);
        }

        if can_assign && self.match_token(TokenType::TokenEqual) {
            self.error("Invalid assignment target.");
        }
    }

    fn get_rule(&self, _type: TokenType) -> ParseRule<'c> {
        return self.rules.get(&_type).cloned().unwrap();
    }

    fn is_lower_precedence(&self, precedence: Precedence) -> bool {
        let current_precedence = self.get_rule(self.tokens[self.current]._type).precedence;
        precedence <= current_precedence
    }

    fn parse_number(&mut self, _can_assign: bool) -> () {
        let value = match self.tokens[self.current - 1].source_str.parse() {
            Ok(v) => v,
            Err(_) => 0.0, //TODO proper error handling
        };

        self.emit_constant(Value::Number(value));
    }

    fn or_(&mut self, _can_assign: bool) -> () {
        let else_jump = self.emit_jump(OpCode::OpJumpIfFalse(0xff)) as usize;
        let end_jump = self.emit_jump(OpCode::OpJump(0xff)) as usize;

        self.patch_jump(else_jump);
        self.emit_byte(OpCode::OpPop);

        self.parse_precedence(Precedence::PrecOr);
        self.patch_jump(end_jump);
    }

    fn make_constant(&mut self, value: Value) -> u8 {
        let constant = u8::from(match self.chunk.add_constant(value) {
            Ok(v) => v,
            Err(_) => {
                println!("Too many constants in one chunk.");
                return 0;
            }
        });

        return constant - 1; //TODO
    }

    fn emit_byte(&mut self, byte: OpCode) -> () {
        self.chunk
            .write_chunk(byte, self.tokens[self.current - 1].line);
    }

    fn emit_bytes(&mut self, byte1: OpCode, byte2: OpCode) -> () {
        self.emit_byte(byte1);
        self.emit_byte(byte2);
    }

    fn emit_loop(&mut self, loop_start: usize) -> () {
        let offset = (self.chunk.code.len() - loop_start + 2) as u16;
        let offset = match u16::try_from(offset) {
            Ok(v) => v,
            Err(_) => {
                self.error("Loop bodey too large.");
                0xffff
            }
        };

        self.emit_byte(OpCode::OpLoop(offset));
    }

    fn emit_jump(&mut self, instruction: OpCode) -> isize {
        self.emit_byte(instruction);
        self.emit_byte(OpCode::OpJumpIfFalse(0xff)); //TODO
        self.emit_byte(OpCode::OpJumpIfFalse(0xff));
        return (self.chunk.code.len() - 2) as isize;
    }

    fn patch_jump(&mut self, offset: usize) -> () {
        // -2 to adjust the bytecode for the jump offset itself
        let jump = (self.chunk.code.len() - 2) as u16;

        if jump > u16::max_value() {
            self.error("Too much code to jump over.");
        }

        self.chunk.code[offset] = OpCode::OpJumpIfFalse((jump >> 8) & 0xff);
        self.chunk.code[offset - 1] = OpCode::OpJumpIfFalse(jump & 0xff);
    }

    fn emit_constant(&mut self, value: Value) -> () {
        let index = self.make_constant(value);
        self.emit_byte(OpCode::OpConstant(index));
    }

    fn emit_return(&mut self) -> () {
        self.emit_byte(OpCode::OpReturn);
    }

    /// Reports an error at the current token, printing a message and entering panic mode.
    /// Ensures that multiple errors don't cascade.
    fn error_at_current(&mut self, msg: &'c str) -> () {
        self.error_at(msg, self.current);
    }

    fn error(&mut self, msg: &'c str) -> () {
        self.error_at(msg, self.current - 1);
    }

    /// Reports an error at a specific token index and switches the parser into panic mode.
    /// This allows the parser to recover and continue parsing after an error is encountered.
    fn error_at(&mut self, msg: &'c str, index: usize) -> () {
        if self.panic_mode {
            return;
        }
        self.panic_mode = true;

        let token = &self.tokens[index];
        print!("[line {}:{}] Error", token.line, token.col);

        match token._type {
            TokenType::TokenEOF => print!(" at end"),
            TokenType::TokenError => print!(""),
            _ => print!(" at '{}'", token.source_str),
        };

        println!(": {}", msg);
        self.had_error = true;
    }
}
